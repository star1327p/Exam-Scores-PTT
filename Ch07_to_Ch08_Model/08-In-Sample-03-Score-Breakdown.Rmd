Let's examine the confusion matrices for each group of **HighSchool_PR**: 0-79, 80-89, 90-94, 95-99. We would like to see if the model performance varies across these groups. Readers can refer to Section \ref{HighSchool-PR-80-up} for the details of this categorization. Before going into the analysis, we need to ensure that each group has a sufficiently large number of respondents within the 188 total records.    

The group with **HighSchool_PR** 0-79 has the smallest number of respondents, and 25 is a sufficient sample size. The groups  with **HighSchool_PR** 80-89 and 90-94 contain 49 and 44 respondents, respectively. The group with **HighSchool_PR** 95-99 includes 70 respondents, which is the largest of the four categories.  

```{r header-code,include=FALSE}
data = read.csv("../ptt_SENIORHIGH_data.csv")
names(data)[1] = "pttID"

missing_rows = which(data$HighSchool_PR == "-1" | data$College_Score == "-1")
data_corr = data[-missing_rows,]

data_corr$CS_65up = data_corr$College_Score >=65

model = glm(CS_65up ~ HighSchool_PR, data=data_corr, family="binomial")

print("This is a test.")
```

```{r breakdown-by-pr}
HS0to79_ind = which(data_corr$HighSchool_PR >=0 & data_corr$HighSchool_PR <= 79)
HS80to89_ind = which(data_corr$HighSchool_PR >= 80 & data_corr$HighSchool_PR <= 89)
HS90to94_ind = which(data_corr$HighSchool_PR >= 90 & data_corr$HighSchool_PR <= 94)
HS95to99_ind = which(data_corr$HighSchool_PR >= 95 & data_corr$HighSchool_PR <= 99)

print(paste("HighSchool_PR 0-79:",length(HS0to79_ind), "respondents"))
print(paste("HighSchool_PR 80-89:",length(HS80to89_ind), "respondents"))
print(paste("HighSchool_PR 90-94:",length(HS90to94_ind), "respondents"))
print(paste("HighSchool_PR 95-99:",length(HS95to99_ind), "respondents"))
```

Now we can produce a confusion matrix for each of the four groups. Except for **HighSchool_PR** 90-94, all the other three groups contain only one value in the predicted outcomes. The higher **HighSchool_PR** the student had, the higher probability the model would predict this student to achieve **College_Score** at least 65. The inference is within our expectations, but we also emphasize that the model is not perfect. There are still some students with a low **HighSchool_PR** but an impressively good **College_Score**.       

- **HighSchool_PR** 0-79 has only FALSE predicted outcomes in **College_Score** at least 65.
- **HighSchool_PR** 80-89 has only FALSE predicted outcomes in **College_Score** at least 65.
- **HighSchool_PR** 90-94 has TRUE and FALSE predicted outcomes in **College_Score** at least 65.
- **HighSchool_PR** 95-99 has only TRUE predicted outcomes in **College_Score** at least 65.  

When the predicted outcomes do not include both TRUE and FALSE, the confusion matrix produced in `R` would be 2x1 instead of the full 2x2. Section \ref{confusion-2x1} shows the incorrect 2x1 confusion matrices, and we will add the missing second column back in Section \ref{confusion-2x2-full}. Finally, we will interpret these results in Section \ref{segment-interpret}.

### Confusion Matrices (Incorrect) {#confusion-2x1}

Let's write a function to summarize the actual outcomes and the predicted outcomes into a confusion matrix, using the default settings in `table`. As the readers can see, `table` outputs only the nonzero columns, and that's why we have several 2x1 confusion matrices here.

```{r confusion-original}
# Data
actual_65up = data_corr$CS_65up
# Predicted results
predicted_65up = model$fitted.values >= 0.5

confusion_original <- function(HS_inds, actual, predicted) {
  actual = actual[HS_inds]
  predicted = predicted[HS_inds]
  confusion = table(actual, predicted)
  return(confusion)
}
```

Confusion matrix for **HighSchool_PR** 0-79

```{r pr-0-79-original}
confusion_0to79 = confusion_original(HS0to79_ind, actual_65up, predicted_65up)
confusion_0to79
```

Confusion matrix for **HighSchool_PR** 80-89

```{r pr-80-89-original}
confusion_80to89 = confusion_original(HS80to89_ind, actual_65up, predicted_65up)
confusion_80to89
```

Confusion matrix for **HighSchool_PR** 90-94

```{r pr-90-94-original}
confusion_90to94 = confusion_original(HS90to94_ind, actual_65up, predicted_65up)
confusion_90to94
```

Confusion matrix for **HighSchool_PR** 95-99

```{r pr-95-99-original}
confusion_95to99 = confusion_original(HS95to99_ind, actual_65up, predicted_65up)
confusion_95to99
```

### Confusion Matrices (Correct) {#confusion-2x2-full}

When the confusion matrix has nonzero values in all four cells, we can output the 2x2 confusion matrix. But before doing so, we need to revert the order of FALSE and TRUE in the rows and columns, since `R` sorts names in alphabetical order by default. This can be done by producing the second index (TRUE) before the first index (FALSE).  

When all predicted values are FALSE, the confusion matrix is missing a TRUE column and we need to add it back. Similarly, When all predicted values are TRUE, the confusion matrix is missing a FALSE column and we also need to add it back. Finally, we revert the order of FALSE and TRUE in the rows and columns, as in the case of an 2x2 confusion matrix.  

By checking the dimensions of the confusing matrices and modifying if necessary, we obtain all four 2x2 confusion matrices for the four categories of **HighSchool_PR**.

```{r confusion-subset}
confusion_subset <- function(HS_inds, actual, predicted) {
  actual = actual[HS_inds]
  predicted = predicted[HS_inds]
  confusion = table(actual, predicted)
  
  # When the confusion matrix has nonzero values in all four cells
  if ((dim(confusion)[1] == 2) && (dim(confusion)[2] == 2)) {
    # Revert the order of FALSE and TRUE
    confusion = confusion[2:1, 2:1]
    # Exit the function because the operation is complete
    return(confusion)
  }
  
  # When all predicted values are FALSE
  else if (colnames(confusion) == c("FALSE")) {
    confusion = as.table(cbind(confusion,c(0,0)))
    colnames(confusion) = c("FALSE","TRUE")
    names(dimnames(confusion)) = c("actual","predicted")
  }
  
  # When all predicted values are TRUE
  else if (colnames(confusion) == c("TRUE")) {
    confusion = as.table(cbind(c(0,0), confusion))
    colnames(confusion) = c("FALSE","TRUE")
    names(dimnames(confusion)) = c("actual","predicted")
  }
  
  # Revert the order of FALSE and TRUE
  confusion = confusion[2:1, 2:1] 
  return(confusion)
}
```

Confusion matrix for **HighSchool_PR** 0-79

```{r pr-0-79-subset}
confusion_0to79 = confusion_subset(HS0to79_ind, actual_65up, predicted_65up)
confusion_0to79
```

Confusion matrix for **HighSchool_PR** 80-89

```{r pr-80-89-subset}
confusion_80to89 = confusion_subset(HS80to89_ind, actual_65up, predicted_65up)
confusion_80to89
```

Confusion matrix for **HighSchool_PR** 90-94

```{r pr-90-94-subset}
confusion_90to94 = confusion_subset(HS90to94_ind, actual_65up, predicted_65up)
confusion_90to94
```

Confusion matrix for **HighSchool_PR** 95-99

```{r pr-95-99-subset}
confusion_95to99 = confusion_subset(HS95to99_ind, actual_65up, predicted_65up)
confusion_95to99
```


### Interpretations {#segment-interpret}

Table \ref{tab:breakdown-pr} shows the model results for each **HighSchool_PR** category (0-79, 80-89, 90-94, 95-99) -- in terms of accuracy, precision, recall, FPR, and FNR. Any metric that cannot be calculated is marked as N/A. The results are quite extreme because the model predicted negative for all **HighSchool_PR** 0-79 and 80-89, and it predicted positive for all **HighSchool_PR** 95-99. Here, positive means achieving **College_Score** 65 or higher, and negative means not achieving this.  

The overall accuracy is slightly above 70%, while the accuracy for **HighSchool_PR** 90-94 is below 50%. Nevertheless, the group of **HighSchool_PR** 90-94 is the only category with nonzero values in all four cells of the confusion matrix. All the other three **HighSchool_PR** categories have good accuracy, but their FPR and FNR are either 0% or 100% because all predictions within each group have the same value.    

\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \textbf{HighSchool$\_$PR}   & Accuracy & Precision & Recall  & FPR     & FNR     \\ \hline
     0-79   & 84.00\% & N/A     & 0\%     & 0\%     & 100\% \\ \hline
    80-89   & 71.43\% & N/A     & 0\%     & 0\%     & 100\% \\ \hline
    90-94   & 45.45\% & 40.54\% & 88.23\% & 81.48\% & 11.76\% \\ \hline
    95-99   & 81.43\% & 81.43\% & 100\%   & 100\%   & 0\%     \\ \hline
    Overall & 70.74\% & 67.29\% & 78.26\% & 36.46\% & 21.74\% \\ \hline
    \end{tabular}
    \caption{Model results for each \textbf{HighSchool$\_$PR} category}
    \label{tab:breakdown-pr}
\end{table}

For **HighSchool_PR** 0-79 and 80-89, the precision is not available (N/A) due to division-by-zero. The model made zero positive predictions, i.e., it predicted all students in the two categories not to achieve **College_Score** 65 or higher. Note that these students had a non-zero probability to obtain this achievement, but their predicted probability is less than the threshold of 50%, and that's why the datapoints are predicted as negative. The remaining metrics of **HighSchool_PR** 0-79 and 80-89 are straightforward, because they are either 0% or 100%. The recall is 0% because none of the students in these categories received a positive prediction. The FPR is also 0% because all students who did not achieve **College_Score** 65 or higher were not predicted to do so anyway. The FNR is 100% because all students who actually obtained **College_Score** 65 or higher were not predicted to make it, so these datapoints are regarded as unexpected successes. Finally, the accuracy here equals to the percentage of students who received **College_Score** below 65, and it is reasonable to see a lower accuracy (non-success rate) for **HighSchool_PR** 80-89 than 70-79.           

**HighSchool_PR** 90-94 is the most interesting group, because it is the only category where the model predicted both TRUE and FALSE values. Although the accuracy is less than 50%, the recall is impressively high (over 80%). The model predicted 37 out of 44 students in this category to achieve **College_Score** 65 or higher, but 22 of the 37 students did not make it. This resulted in a high FPR and a low FNR. Section \ref{college-60-up} shows that a **College_Score** of 65 is around the 95th percentile of all college entrance exam takers in Taiwan each year. Nevertheless, we should give students the benefit of doubt, and predict that most students with **HighSchool_PR** 90-94 are going to achieve **College_Score** at least 65. Note that not all high school students are willing and able to attend college. Moreover, students with **HighSchool_PR** 90-94 may not have the same level of access to academic resources, depending on which region they live in. **HighSchool_PR** 90-94 can mean attending a top high school in the rural areas.^[<https://www.ptt.cc/bbs/SENIORHIGH/M.1671768145.A.2B9.html>] But in Taipei, this **HighSchool_PR** is nowhere sufficient to get admitted into any prestigious high schools (a.k.a. "the top three") within the city.^[<https://cclccl-life.blogspot.com/2013/06/blog-post_9.html>] Since we do not have the geographic information of the respondents, we cannot make any inferences on which ones with **HighSchool_PR** 90-94 are more likely to achieve **College_Score** at least 65.  

The **HighSchool_PR** 95-99 group contains respondents with top 5% scores in the high school entrance exam, and that's why the model predicted all of them to achieve **College_Score** at least 65. The recall is 100% due to all datapoints being predicted as TRUE. The FPR is also 100% because all respondents in this category who did not achieve **College_Score** at least 65 were predicted to do so. The FNR is 0% because none of the respondents were predicted not to achieve this. The accuracy is over 80% because most respondents with **HighSchool_PR** 95-99 actually obtained **College_Score** at least 65. The 4x4 table in Section \ref{bivariate-top-scorers} shows that 23 of them (32.86%) got **College_Score** between 65 and 69, while 34 of them (48.57%) got **College_Score** between 70 and 75. One extension would be increasing the **College_Score** cutoff point to 70 for this group, but we do not think this is practical without external data about these respondents.  

In our opinion, **HighSchool_PR** 95-99 does little in distinguishing students' academic capabilities within the group, because it is possible to drop one percentile by getting just one critical question wrong on the high school entrance exam. Prior to 2009, there was a huge score difference between full marks and missing by just one question.^[<https://news.ltn.com.tw/news/life/paper/217325>] This could result in a significant difference of **HighSchool_PR**, because missing five questions in a single subject (full marks on the other four) would have a better score than missing one question in each of the five subjects. Hence it is not meaningful to evaluate students' academic performance solely from **HighSchool_PR**. Similar to the case in **HighSchool_PR** 90-94, we cannot make inferences about the within-group differences of **HighSchool_PR** 95-99. In rural areas, students with **HighSchool_PR** 95-99 already meet the admission requirements for the top high school in their region. Almost all of them would attend that school unless they move to a different region. As a comparison, Taipei's first choice high school requires **HighSchool_PR** at least 99, second choice requires at least 98, and third choice requires at least 97.^[<https://chendaneyl.pixnet.net/blog/post/31436728>] As a result, students in Taipei with **HighSchool_PR** 95 or 96 often end up attending local high schools outside the top tier. These schools are still high-quality and provide ample resources, but they are not as prestigious as the top three choices.  