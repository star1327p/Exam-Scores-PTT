We retrieved data from the SENIORHIGH (high school)^[<https://www.ptt.cc/bbs/SENIORHIGH/M.1432729401.A.995.html>] discussion section on PTT,^[If you have a PTT account, you can log into the website using a browser. <https://term.ptt.cc/>] the largest terminal-based bulletin board in Taiwan.^[<https://en.wikipedia.org/wiki/PTT_Bulletin_Board_System>] The data are stored in the file `ptt_SENIORHIGH_data.csv`.^[https://github.com/star1327p/Exam-Scores-PTT/blob/master/ptt_SENIORHIGH_data.csv] The data from PTT are more representative than if we had collected on our own, because almost anyone could get a PTT account and reply to the post. The majority of scores were reported in May 2015, and a few scores were reported in the following month or later. The records indicate that each respondent had taken the college entrance exam in the year 2015 or earlier, so we can safely assume that neither of them had taken the new form of high school entrance exam starting in 2014.   

It is a challenge to obtain individual pairs of data as a representative sample. Although it is easy to send out a spreadsheet and ask our friends to report their scores anonymously, this approach can result in a large selection bias. Many of our friends graduated from the same high school and/or college, so we are likely to have similar entrance exam scores. That's why we turned to the public forum PTT to reduce selection bias in the data collection.   

Data in the real world are messy, and data scientists spend lots of time cleaning (preprocessing) the data, i.e., preparing the data for analysis.^[<https://bit.ly/303IWxY>] But data cleaning is a necessary step for better analysis results, and there are some visualization examples that demonstrate the importance of preprocessing the data \cite{chai2020importance}. Our dataset `ptt_SENIORHIGH_data.csv` is relatively clean, but we still have to recode and flag some anomaly values.   

## Flagging Values in Data

The dataset `ptt_SENIORHIGH_data.csv` contains 197 rows, and the main variables are:

- **pttID**: Each person's ID on PTT, which can be anonymous. This column serves as the unique identifier of each person.
- **HighSchool_PR**: Each person's percentile rank (PR) of the high school entrance exam in Taiwan, ranging from 0 to 99.
- **College_Score**: Each person's General Scholastic Ability Test (GSAT) score, ranging from 0 to 75.  

There are 6 missing values in **HighSchool_PR** and 3 missing values in **College_Score**, so each of them is recorded as "-1" (an invalid numerical value for the scores). In the data entry process, invalid scores like **HighSchool_PR** 100 are also treated as missing.     

In some cases, the reported scores can be inaccurate based on the respondent's description, so we read the comments and manually created two indicators for this issue. Note that **inaccurate scores are still valid**, so we keep them in the data analysis.    

- **HS_Inacc**: A "1" means the reported **HighSchool_PR** is inaccurate.
- **CS_Inacc**: A "1" means the reported **College_Score** is inaccurate.    

For **HS_Inacc** and **CS_Inacc**, we set the missing values to "0" because the two flags are binary indicators. Otherwise, the missing values would show as `NA`, which are difficult to process in the code.  

```{r data-cleaning-inaccurate-flags}
data = read.csv("ptt_SENIORHIGH_data.csv")

names(data)[1] = "pttID" # system read in as "i..pttID", need to correct this

data$HS_Inacc[is.na(data$HS_Inacc)] = 0
data$CS_Inacc[is.na(data$CS_Inacc)] = 0
```

One obvious reason of inaccurate scores is that a respondent may comment that his/her scores are approximate. Moreover, some people reported their **HighSchool_PR** from the mock exam, rather than from the actual high school entrance exam. In 2012 and 2013, the Ministry of Education in Taiwan allowed students to apply for high schools with their grades in middle school. During that time, if a student got admitted to a high school using this method, he/she would not need to take the high school entrance exam.^[<https://tsjh301.blogspot.com/2014/06/compulsory-education.html>]   

For **College_Score**, the approximation clause still applies. In addition, there are two college entrance exams in each school year, and some students may do much better on the second exam than the first one. Then they were admitted to a more prestigious school than the first exam score had indicated, so this is also a form of inaccuracy.  

We add two more indicators to signal invalid (impossible) values in **HighSchool_PR** and **College_Score**.  

- **HS_Invalid**: A "1" means the reported **HighSchool_PR** is invalid, i.e., outside the range of 1-99.
- **CS_Invalid**: A "1" means the reported **College_Score** is invalid, i.e., outside the range of 1-75.  

Again, we set **HS_Invalid** to "0" for a valid **HighSchool_PR**, and set **CS_Invalid** to "0" for a valid **College_Score**.  

```{r data-cleaning-invalid-flags}
data$HS_Invalid = 0
data$HS_Invalid[(data$HighSchool_PR > 99)|(data$HighSchool_PR < 1)] = 1

data$CS_Invalid = 0
data$CS_Invalid[(data$College_Score > 75)|(data$College_Score < 1)] = 1
```

Finally, we save the clean version to a separate `.csv` file for future use.  

```{r save-data-clean, eval=FALSE}
write.csv(data, "ptt_SENIORHIGH_data_clean.csv")
```

## Data Snapshot

We show the first 10 rows of data here, and we already see several anomalies that are flagged. For example, the 1st respondent `game275415` provided an approximate value to the **HighSchool_PR**, so we marked this value as inaccurate and a "1" in **HS_Inacc**. The 4th respondent `heejung` used mock exam scores for the **HighSchool_PR**, so this score is also marked as inaccurate. The 6th respondent `robinyu85` claimed to not having taken the high school entrance exam at all, so his/her missing **HighSchool_PR** is encoded to "-1" and flagged as invalid.   

We also observed that **pttID** contains some information for potential inference, although we are not going to use it. For example, the 6th respondent `robinyu85` could be someone named Robin Yu, and the 8th respondent `godpatrick11` may have the English name Patrick. Nevertheless, this kind of information is simply a heuristic, so it is neither sufficient nor appropriate to include in the data analysis.  

```{r set-width, include=FALSE}
default_value = getOption("width") # 80
# print(default_value)

# Increase the width to print all data column names on a single line.
options(width = 200)
```

```{r raw-data}
data[1:10,]
```

```{r restore-width, include=FALSE}
# Now we reset the width back to default for the rest of the document.
options(width = default_value)
```


## Bivariate Validation

We need to clean up the data to prepare for the analysis. For example, we would like to investigate the relationship between **HighSchool_PR** and **College_Score**, so we need to ensure that each record consists of both valid scores. There are 191 records of valid **HighSchool_PR** numbers in the data, but if we consider only the ones with a valid **College_Score**, the number of available records drops to 188. Although which version we use does not matter much when we look at the univariate distribution, this will be problematic when we combine the univariate analysis with the bivariate analysis. Thus, we should use only the 188 records whose **College_Score** numbers are also valid.  

```{r high-school-pr80up-univ}
# High school entrance exam scores: Keep only valid numbers
uni_HS_score = data$HighSchool_PR[which(data$HS_Invalid == 0)]
length(uni_HS_score)
```

The same requirement also applies to **College_Score**. There are 194 records of valid **College_Score** numbers in the data, but only 188 of them also have corresponding valid **HighSchool_PR** numbers.   

```{r college-score60up}
# College entrance exam scores: Keep only valid numbers
uni_college_score = data$College_Score[which(data$CS_Invalid == 0)]
length(uni_college_score)
```

We do not have enough information to impute the few missing values in our dataset, so we decided to exclude them from our analysis. There are nine records with invalid or missing values, and we can locate their indices in the data.   

```{r data-missing-indices}
missing_rows = which(data$HS_Invalid == 1 | data$CS_Invalid == 1)
missing_rows
```

**Remark**: With larger and/or more complex datasets, researchers often apply record linkage methods \cite{dusetzina2014overview} to impute missing or erroneous values in one dataset from another. This is outside the scope of this manuscript.   

Now we build the `R` dataframe `data_corr` (short for "data correlation") for the bivariate analysis. This dataframe excludes any record with at least one missing value in **HighSchool_PR** or **College_Score**.   

```{r data-corr-defined}
# Remove missing data
data_corr = data[-missing_rows,]
```

Again, we show the first 10 rows of `data_corr`, and all values in ` HighSchool_PR` and `College_Score` are valid. The indicators `HS_Invalid` and `CS_Invalid` should be zero throughout this version of data.  

```{r set-width-again, include=FALSE}
default_value = getOption("width") # 80
# print(default_value)

# Increase the width to print all data column names on a single line.
options(width = 200)
```

```{r data-corr-view}
data_corr[1:10,]
```

```{r restore-width-again, include=FALSE}
# Now we reset the width back to default for the rest of the document.
options(width = default_value)
```

The function `dim` retrieves the dimensions of the `R` dataframe `data_corr`. The output reveals that the dataset contains 188 rows and 7 columns, where the 188 rows refer to the 188 records with a valid score in both `HighSchool_PR` and `College_Score`.  

```{r data-corr-size}
dim(data_corr)
```

Alternatively, we can also use the function `length` to find the number of elements in an array. This shows both columns `HighSchool_PR` and `College_Score` contain 188 elements each. Note that `length` does not distinguish between missing and non-missing values. A missing element, often denoted as `NA`, is still counted as one element. 

```{r high-school-pr80up-bivar}
length(data_corr$HighSchool_PR)
```

```{r college-score60up-bivar}
length(data_corr$College_Score)
```

**Remark**: Readers new to `R` programming may wonder where we can find the type of each object, in order to determine how to proceed next. The function `class` returns the type of the input object, and the output confirms that `data_corr` is an `R` dataframe. Then we can leverage the functions available for this data structure.  

```{r check-data-type}
class(data_corr)
```

